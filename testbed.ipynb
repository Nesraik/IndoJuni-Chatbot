{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from availableTools import IndoJuniTool\n",
    "from langfuse import Langfuse\n",
    "from langfuse.openai import OpenAI\n",
    "from langfuse.decorators import observe\n",
    "import json\n",
    "from Utils.jinjaProcessor import *\n",
    "from Utils.parser import *\n",
    "from rag import *\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)\n",
    "langfuse = Langfuse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Chatbot(IndoJuniTool):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.api_keys = []\n",
    "        self.current_index = 0\n",
    "        self._insert_api_key()\n",
    "        self.tools_prompt = process_template_no_var('Prompt/tools_template.jinja')\n",
    "        self.functions = {\n",
    "            \"getCurrentCart\": self.getCurrentCart,\n",
    "            \"addProduct\": self.addProduct,\n",
    "            \"modifyCart\": self.modifyCart,\n",
    "        }\n",
    "        self.Retriever = ContextRetriever()\n",
    "\n",
    "    def _insert_api_key(self):\n",
    "        with open(\"llm_api_keys.txt\") as f:\n",
    "            for line in f.readlines():\n",
    "                self.api_keys.append(line.strip())\n",
    "\n",
    "    def _get_client(self):\n",
    "        return OpenAI(\n",
    "            base_url=os.environ.get(\"CHATBOT_BASE_URL\"),\n",
    "            api_key= self.api_keys[self.current_index]\n",
    "        )\n",
    "    \n",
    "    @observe()\n",
    "    def generate_response(self,messages):\n",
    "        try:\n",
    "            client = self._get_client()\n",
    "            response = client.chat.completions.create(\n",
    "                model = os.environ.get(\"CHATBOT_MODEL\"),\n",
    "                messages = messages,\n",
    "                temperature=0.1,\n",
    "                top_p=0.1,\n",
    "                presence_penalty=0.0,\n",
    "                frequency_penalty=0.0,\n",
    "            )\n",
    "        except requests.exceptions.HTTPError as e:\n",
    "            if response.status_code == 429:\n",
    "                self.current_index = (self.current_index + 1) % len(self.api_keys)\n",
    "                client = self._get_client()\n",
    "                response = client.chat.completions.create(\n",
    "                    model = \"llama-3.3-70b-versatile\",\n",
    "                    messages = messages,\n",
    "                    temperature=0.1,\n",
    "                    top_p=0.1,\n",
    "                    presence_penalty=0.0,\n",
    "                    frequency_penalty=0.0,\n",
    "                )\n",
    "        return response.choices[0].message.content\n",
    "\n",
    "    def end_response(self,tool_call):\n",
    "        end_response_func = [\"NONE\"]\n",
    "        if tool_call['function_name'] in end_response_func:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def generate_single_chat_message(self,user_prompt,messages,flag):\n",
    "\n",
    "        context = self.Retriever.retrieveContext(user_message=user_prompt,chat_history=messages)\n",
    "\n",
    "        temp = {\n",
    "            \"tools\": self.tools_prompt,\n",
    "            \"context\": context\n",
    "        }\n",
    "\n",
    "        system_prompt = process_template('Prompt/system_prompt.jinja', temp)\n",
    "\n",
    "        if flag == False:\n",
    "            messages = [\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": system_prompt\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": user_prompt\n",
    "                }\n",
    "            ]\n",
    "            flag = True\n",
    "        else:\n",
    "            messages.append({\n",
    "                \"role\": \"user\",\n",
    "                \"content\": user_prompt\n",
    "            })\n",
    "            messages[0]['content'] = system_prompt\n",
    "\n",
    "        while True:\n",
    "            response = self.generate_response(messages)\n",
    "            messages.append({\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": response\n",
    "            })\n",
    "\n",
    "            \n",
    "            tools = parse_function(response,bfcl_format=False)\n",
    "\n",
    "            if len(tools) == 1 and (tools[0]['function_name'] == 'FUNCTION_NOT_FOUND' or tools[0]['function_name'] == 'NONE'):\n",
    "                break\n",
    "            \n",
    "            \n",
    "            for tool in tools:\n",
    "\n",
    "                if tool['function_name'] == 'FUNCTION_NOT_FOUND' or tool['function_name'] == 'NONE':\n",
    "                    continue\n",
    "\n",
    "                # Check for function name\n",
    "                try:\n",
    "                    function_name = self.functions[tool['function_name']]\n",
    "                except:\n",
    "                    messages.append({\n",
    "                        \"role\": \"tool\",\n",
    "                        \"tool_call_id\": \"N/A\",\n",
    "                        \"content\": \"Function not found in tools_dict\"\n",
    "                    })\n",
    "\n",
    "                    continue\n",
    "\n",
    "                try:\n",
    "                    function_args = tool['args']\n",
    "                except:\n",
    "                    function_args = tool['parameters']\n",
    "\n",
    "                if \"<MISSING>\" in function_args.values():\n",
    "                    return messages, flag\n",
    "\n",
    "                # Check for function arguments\n",
    "                try:    \n",
    "                    function_output = function_name(**function_args)\n",
    "                    content = json.dumps(function_output, indent=4)\n",
    "                    messages.append({\n",
    "                        \"role\": \"tool\",\n",
    "                        \"tool_call_id\": function_output['tool_call_id'],\n",
    "                        \"content\": content\n",
    "                    })\n",
    "\n",
    "                except Exception as e:\n",
    "                    messages.append({\n",
    "                        \"role\": \"tool\",\n",
    "                        \"tool_call_id\": \"N/A\",\n",
    "                        \"content\": f\"Error: {str(e)} calling {function_name.__name__} with args {function_args}\"\n",
    "                    })\n",
    "\n",
    "        return messages, flag\n",
    "    \n",
    "    def run_conversation(self):\n",
    "        messages = []\n",
    "        flag = False\n",
    "\n",
    "        count = 0\n",
    "        while True:\n",
    "            \n",
    "            tester_message = input(\"Tester Message: \")\n",
    "            if tester_message.strip().lower() == 'exit':\n",
    "                print(\"Exiting the chatbot.\")\n",
    "                break\n",
    "                \n",
    "            messages, flag = self.generate_single_chat_message(tester_message, messages,flag)\n",
    "\n",
    "            count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "OpenAIError",
     "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOpenAIError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m chatbot \u001b[38;5;241m=\u001b[39m \u001b[43mChatbot\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m chatbot\u001b[38;5;241m.\u001b[39mrun_conversation()\n",
      "Cell \u001b[1;32mIn[2], line 13\u001b[0m, in \u001b[0;36mChatbot.__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtools_prompt \u001b[38;5;241m=\u001b[39m process_template_no_var(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPrompt/tools_template.jinja\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunctions \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgetCurrentCart\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgetCurrentCart,\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maddProduct\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maddProduct,\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodifyCart\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodifyCart,\n\u001b[0;32m     12\u001b[0m }\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mRetriever \u001b[38;5;241m=\u001b[39m \u001b[43mContextRetriever\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\usern\\OneDrive\\Desktop\\Pre thesis\\Prototype\\Utils\\rag.py:36\u001b[0m, in \u001b[0;36mContextRetriever.__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m---> 36\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient \u001b[38;5;241m=\u001b[39m \u001b[43mOpenAI\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[43m        \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menviron\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGeminiAPI\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbase_url\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menviron\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGEMINI_BASE_URL\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_name \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGEMINI_MODEL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdbname\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIndoJuni\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n",
      "File \u001b[1;32mc:\\Users\\usern\\anaconda3\\envs\\Deepseek_related\\lib\\site-packages\\openai\\_client.py:110\u001b[0m, in \u001b[0;36mOpenAI.__init__\u001b[1;34m(self, api_key, organization, project, base_url, websocket_base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[0m\n\u001b[0;32m    108\u001b[0m     api_key \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m api_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 110\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OpenAIError(\n\u001b[0;32m    111\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    112\u001b[0m     )\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key \u001b[38;5;241m=\u001b[39m api_key\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m organization \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mOpenAIError\u001b[0m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
     ]
    }
   ],
   "source": [
    "chatbot = Chatbot()\n",
    "chatbot.run_conversation()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deepseek_related",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
