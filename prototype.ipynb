{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from availableTools import *\n",
    "from langfuse import Langfuse\n",
    "from langfuse.openai import OpenAI\n",
    "from langfuse.decorators import observe\n",
    "import json\n",
    "from Utils.jinjaProcessor import *\n",
    "from Utils.parser import *\n",
    "from Utils.rag import *\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)\n",
    "langfuse = Langfuse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Chatbot:\n",
    "    def __init__(self):\n",
    "        self.api_keys = []\n",
    "        self.current_index = 0\n",
    "        self.insert_api_key()\n",
    "        self.tools = process_template_no_var('Prompt/tools_template.jinja')\n",
    "        self.functions = {\n",
    "            \"getProductList\": getProductList,\n",
    "            \"getCurrentCart\": getCurrentCart,\n",
    "            \"addProduct\": addProduct,\n",
    "            \"modifyCart\": modifyCart,\n",
    "            \"removeProduct\": removeProduct,\n",
    "            \"greetings\": greetings,\n",
    "        }\n",
    "        try:\n",
    "            self.dbcollection = createDbCollection(\n",
    "                dbname=\"IndoJuni\",\n",
    "                filename=\"Knowledge base/productCatalog.json\",\n",
    "                dbpath=\"VectorDB\"\n",
    "            )\n",
    "        except Exception as e:\n",
    "            self.dbcollection = getDbCollection(\n",
    "                dbpath=\"VectorDB\",\n",
    "                dbname=\"IndoJuni\"\n",
    "            )\n",
    "\n",
    "    def insert_api_key(self):\n",
    "        with open(\"llm_api_keys.txt\") as f:\n",
    "            for line in f.readlines():\n",
    "                self.api_keys.append(line.strip())\n",
    "    \n",
    "    def get_client(self,index):\n",
    "        return OpenAI(\n",
    "            base_url=\"https://api.groq.com/openai/v1\",\n",
    "            api_key= self.api_keys[index]\n",
    "        )\n",
    "    \n",
    "    @observe()\n",
    "    def generate_response(self,messages,current_index):\n",
    "        try:\n",
    "            client = self.get_client(current_index)\n",
    "            response = client.chat.completions.create(\n",
    "                model = \"llama-3.3-70b-versatile\",\n",
    "                messages = messages,\n",
    "                temperature=0.1,\n",
    "                top_p=0.1,\n",
    "                presence_penalty=0.0,\n",
    "                frequency_penalty=0.0,\n",
    "            )\n",
    "        except requests.exceptions.HTTPError as e:\n",
    "            if response.status_code == 429:\n",
    "                current_index = (current_index + 1) % len(self.api_keys)\n",
    "                client = self.get_client(current_index)\n",
    "                response = client.chat.completions.create(\n",
    "                    model = \"llama-3.3-70b-versatile\",\n",
    "                    messages = messages,\n",
    "                    temperature=0.1,\n",
    "                    top_p=0.1,\n",
    "                    presence_penalty=0.0,\n",
    "                    frequency_penalty=0.0,\n",
    "                )\n",
    "        return response\n",
    "\n",
    "    def end_response(self,tool_call):\n",
    "        end_response_func = [\"NONE\"]\n",
    "        if tool_call['function_name'] in end_response_func:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def generate_single_chat_message(self,user_prompt,messages,flag):\n",
    "    \n",
    "        chat_message = []\n",
    "\n",
    "        self.dbcollection = getDbCollection(dbpath=\"Data/Chroma databases/Applestore\",dbname=\"Applestore\")\n",
    "\n",
    "        context = RAG(dbcollection=self.dbcollection,\n",
    "                    query=user_prompt)\n",
    "\n",
    "        temp = {\n",
    "            \"tools\": self.tools,\n",
    "            \"context\": context\n",
    "        }\n",
    "\n",
    "        system_prompt = process_template('Prompt/system_prompt.jinja', temp)\n",
    "\n",
    "        if flag == False:\n",
    "            messages = [\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": system_prompt\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": user_prompt\n",
    "                }\n",
    "            ]\n",
    "            flag = True\n",
    "        else:\n",
    "            messages.append({\n",
    "                \"role\": \"user\",\n",
    "                \"content\": user_prompt\n",
    "            })\n",
    "            messages[0]['content'] = system_prompt\n",
    "\n",
    "        while True:\n",
    "            response = self.generate_response(messages)\n",
    "            messages.append({\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": response\n",
    "            })\n",
    "\n",
    "            \n",
    "            tools = parse_function(response,bfcl_format=False)\n",
    "\n",
    "            if len(tools) == 1 and (tools[0]['name'] == 'FUNCTION_NOT_FOUND' or tools[0]['name'] == 'NONE'):\n",
    "                break\n",
    "            \n",
    "            \n",
    "            for tool in tools:\n",
    "\n",
    "                if tool['name'] == 'FUNCTION_NOT_FOUND' or tool['name'] == 'NONE':\n",
    "                    continue\n",
    "\n",
    "                # Check for function name\n",
    "                try:\n",
    "                    function_name = self.functions[tool['name']]\n",
    "                except:\n",
    "                    messages.append({\n",
    "                        \"role\": \"tool\",\n",
    "                        \"tool_call_id\": \"N/A\",\n",
    "                        \"content\": \"Function not found in tools_dict\"\n",
    "                    })\n",
    "\n",
    "                    continue\n",
    "\n",
    "                try:\n",
    "                    function_args = tool['args']\n",
    "                except:\n",
    "                    function_args = tool['parameters']\n",
    "\n",
    "                if \"<MISSING>\" in function_args.values():\n",
    "                    return messages, flag, context, chat_message\n",
    "\n",
    "                # Check for function arguments\n",
    "                try:    \n",
    "                    function_output = function_name(**function_args)\n",
    "                    content = json.dumps(function_output, indent=4)\n",
    "                    messages.append({\n",
    "                        \"role\": \"tool\",\n",
    "                        \"tool_call_id\": function_output['tool_call_id'],\n",
    "                        \"content\": content\n",
    "                    })\n",
    "\n",
    "                except Exception as e:\n",
    "                    messages.append({\n",
    "                        \"role\": \"tool\",\n",
    "                        \"tool_call_id\": \"N/A\",\n",
    "                        \"content\": f\"Error: {str(e)} calling {function_name.__name__} with args {function_args}\"\n",
    "                    })\n",
    "\n",
    "        return messages, flag, context, chat_message\n",
    "    \n",
    "    def run_conversation(self):\n",
    "        messages = []\n",
    "        flag = False\n",
    "\n",
    "        count = 0\n",
    "        while True:\n",
    "            \n",
    "            tester_message = input(\"Tester Message: \")\n",
    "            if tester_message.strip().lower() == 'exit':\n",
    "                print(\"Exiting the chatbot.\")\n",
    "                break\n",
    "                \n",
    "            messages, flag, context, chat_message = self.generate_single_chat_message(tester_message, messages,flag)\n",
    "\n",
    "            count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deepseek_related",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
